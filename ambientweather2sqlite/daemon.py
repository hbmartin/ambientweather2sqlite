import json
import logging
import sys
import time
from datetime import datetime
from http.client import HTTPException
from pathlib import Path

from ambientweather2sqlite import mureq
from ambientweather2sqlite.awparser import extract_values
from ambientweather2sqlite.server import Server

from .database import insert_observation
from .metadata import create_metadata


def clear_lines(n: int) -> None:
    for _ in range(n):
        print("\033[A\033[K", end="")


def wait_for_next_update(period_seconds: int) -> None:
    for i in range(period_seconds, 0, -1):
        print(f"\033[KNext update in {i} seconds", end="\r")
        time.sleep(1)


def start_daemon(
    live_data_url: str,
    database_path: str,
    *,
    port: int | None = None,
    period_seconds: int = 60,
) -> None:
    print(f"Observing {live_data_url}")
    print("Press Ctrl+C to stop")

    log_path = Path(database_path).parent / f"{Path(database_path).stem}_daemon.log"

    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[logging.FileHandler(str(log_path))],
    )
    logger = logging.getLogger(__name__)

    def log_message(message: str) -> None:
        logger.info(message)

    labels: dict[str, str] = {}
    try:
        labels, _ = create_metadata(database_path, live_data_url)
    except (HTTPException, TimeoutError) as e:
        log_message(f"{type(e).__name__}\n{e}")
        print(f"Error fetching metadata: {e}")

    server = None

    if port is not None:
        host = "localhost"
        print(f"Starting JSON server on http://{host}:{port}")
        server = Server(live_data_url, database_path, port, host)
        server.start()

    remove_newlines = 0
    try:
        while True:
            clear_lines(remove_newlines)
            try:
                body = mureq.get(live_data_url)
                live_data = extract_values(body)
            except TimeoutError:
                log_message("TimeoutError")
                print("Warming up weather station's server...")
                remove_newlines = 1
                continue
            except HTTPException as e:
                log_message(f"{type(e).__name__}\n{e}")
                print(f"Error fetching live data: {e}")
                remove_newlines = 1
                wait_for_next_update(period_seconds)
                continue
            print(f"Updated at: {datetime.now()}")
            labeled_data = {
                labels.get(key, key): value for key, value in live_data.items()
            }
            pretty_data = json.dumps(labeled_data, indent=4)
            # + 2 for the "Updated at" line and the newline generated by print()
            remove_newlines = pretty_data.count("\n") + 2
            print(pretty_data)
            insert_observation(database_path, live_data)
            wait_for_next_update(period_seconds)
    except KeyboardInterrupt:
        print(f"\nStopping... results saved to {database_path}")
        if server is not None:
            server.shutdown()
        sys.exit(0)
